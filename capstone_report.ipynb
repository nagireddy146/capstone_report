{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary packages at the starting itself\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the training set features\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set features in df dataframe contain two out of the three outputs we\n",
    "are predicting as output with our algorithms (water quality and water quantity).\n",
    "For each of the three output predictions, we are using the other two as input\n",
    "features (i.e., water quality and functionality of pump are both predictors for\n",
    "water quantity, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading training set lables for functionality of pumps\n",
    "labels=pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #adding labels to the dataframe\n",
    "df['labels']=labels['status_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dropping the Repetitive features***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping variables that were deemed repetitive/not useful\n",
    "df =df.drop(columns=['id','wpt_name', 'num_private', 'subvillage', 'region', 'district_code', 'lga', 'ward', 'recorded_by', 'scheme_name', 'extraction_type_group', 'payment', 'water_quality', 'quantity', 'source_type', 'waterpoint_type_group'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#creating a new variable of \"age\" from the construction_year and date_recorded raw features\n",
    "df['date_recorded'] = df['date_recorded'].astype(str).str[:-6] #getting the year of the date recorded\n",
    "df['age']=df['date_recorded'].astype(int)-df['construction_year']\n",
    "ind = df['age']>2000\n",
    "df['age'][ind]=np.nan #if there is no construction date set the age to NaN\n",
    "\n",
    "df = df.drop(columns = ['date_recorded', 'construction_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#editing variable from hundreds of categories to funder = 1 if village/villagers, 0 otherwise\n",
    "df['funder']=df['funder'].fillna('0')\n",
    "df['funder'] = df['funder'].str.contains('|'.join(['Village','village'])).astype(int) #binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#places with 0 longitude and 2e-08 latitude had missing data for those 2 features\n",
    "ind = df['longitude']==0.0\n",
    "df['longitude'][ind]=np.nan\n",
    "ind = df['latitude']==-2e-08\n",
    "df['latitude'][ind]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similar to funder, reducint from hundreds of categories to installer = 1 if village/villagers, 0 otherwise\n",
    "df['installer']=df['installer'].fillna('0')\n",
    "df['installer'] = df['installer'].str.contains('|'.join(['Village','village'])).astype(int) #binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#from T/F to 0/1\n",
    "ind = df.notna()['public_meeting']\n",
    "df['public_meeting'][ind]=df['public_meeting'][ind].astype(int)\n",
    "ind = df.notna()['permit']\n",
    "df['permit'][ind]=df['permit'][ind].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here begins One Hot Encoding (OHE) for all remaining features\n",
    "new_basin = np.asarray(df['basin']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False, categories='auto')\n",
    "a = enc.fit_transform(new_basin)\n",
    "for num,i in enumerate(np.unique(df['basin'])):\n",
    "    df['basin_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'basin')\n",
    "\n",
    "new_region = np.asarray(df['region_code']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False, categories='auto')\n",
    "a = enc.fit_transform(new_region)\n",
    "for num,i in enumerate(np.unique(df['region_code'])):\n",
    "    df['region_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'region_code')\n",
    "\n",
    "df['scheme_management'] = df['scheme_management'].fillna('znan')\n",
    "new_scheme = np.asarray(df['scheme_management']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False, categories='auto')\n",
    "a = enc.fit_transform(new_scheme)\n",
    "for num,i in enumerate(np.unique(df['scheme_management'])):\n",
    "    df['scheme_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = ['scheme_znan', 'scheme_management'])\n",
    "\n",
    "new_extype = np.asarray(df['extraction_type']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False, categories='auto')\n",
    "a = enc.fit_transform(new_extype)\n",
    "for num,i in enumerate(np.unique(df['extraction_type'])):\n",
    "    df['exttype_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'extraction_type')\n",
    "\n",
    "\n",
    "new_extypeclass = np.asarray(df['extraction_type_class']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False, categories='auto')\n",
    "a = enc.fit_transform(new_extypeclass)\n",
    "for num,i in enumerate(np.unique(df['extraction_type_class'])):\n",
    "    df['exttypeclass_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'extraction_type_class')\n",
    "\n",
    "\n",
    "new_mgmt = np.asarray(df['management']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False, categories='auto')\n",
    "a = enc.fit_transform(new_mgmt)\n",
    "for num,i in enumerate(np.unique(df['management'])):\n",
    "    df['mgmt_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'management')\n",
    "\n",
    "\n",
    "new_mgmtgp = np.asarray(df['management_group']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_mgmtgp)\n",
    "for num,i in enumerate(np.unique(df['management_group'])):\n",
    "    df['mgmtgp_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'management_group')\n",
    "\n",
    "\n",
    "new_paytype = np.asarray(df['payment_type']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_paytype)\n",
    "for num,i in enumerate(np.unique(df['payment_type'])):\n",
    "    df['paytype_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'payment_type')\n",
    "\n",
    "\n",
    "new_source = np.asarray(df['source']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_source)\n",
    "for num,i in enumerate(np.unique(df['source'])):\n",
    "    df['source_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'source')\n",
    "\n",
    "\n",
    "new_sourceclass = np.asarray(df['source_class']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_sourceclass)\n",
    "for num,i in enumerate(np.unique(df['source_class'])):\n",
    "    df['sourceclass_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'source_class')\n",
    "\n",
    "\n",
    "new_wpt = np.asarray(df['waterpoint_type']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_wpt)\n",
    "for num,i in enumerate(np.unique(df['waterpoint_type'])):\n",
    "    df['wpttype_'+str(i)] = a[:,num]\n",
    "df = df.drop(columns = 'waterpoint_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting functionality\n",
    "df_functional = df.copy()\n",
    "new_qual = np.asarray(df_functional['quality_group']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_qual)\n",
    "for num,i in enumerate(np.unique(df_functional['quality_group'])):\n",
    "    df_functional['quality_'+str(i)] = a[:,num]\n",
    "df_functional = df_functional.drop(columns = 'quality_group')\n",
    "\n",
    "\n",
    "new_quant = np.asarray(df_functional['quantity_group']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_quant)\n",
    "for num,i in enumerate(np.unique(df_functional['quantity_group'])):\n",
    "    df_functional['quantity_'+str(i)] = a[:,num]\n",
    "df_functional = df_functional.drop(columns = 'quantity_group')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1)Functionality Prediction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling NANs with mean of variable\n",
    "df_func = df_functional.fillna(df_functional.mean())\n",
    "\n",
    "#separating into test (25%) and train (75%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_func.drop(columns='labels'), df_func['labels'], test_size=0.25, random_state=0)\n",
    "\n",
    "#three classes of our output variable\n",
    "classes=['Functional', 'Needs Repair', 'Non-Functional']\n",
    "\n",
    "#Encoding the three output classes into integers\n",
    "\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(y_test)\n",
    "test_labels = enc.transform(y_test)\n",
    "\n",
    "# SMOTE resampling to deal with class imbalance\n",
    "sm = SMOTE()\n",
    "x_res,y_res = sm.fit_resample(x_train,y_train)\n",
    "\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(y_res)\n",
    "train_labels = enc.transform(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_res,train_labels)\n",
    "y_pred=logreg.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#optimizing hyperparameters\n",
    "\"\"\"\n",
    "We used GridSearchCV which performs k-fold cross validation (k=5 for us) and searches\n",
    "a grid of specified parameters to find the best parameters.\n",
    "\"\"\"\n",
    "param_dist = {\n",
    "'penalty': ['l1','l2'],\n",
    "'C': [0.001,0.01,0.5,1]\n",
    "}\n",
    "\n",
    "lr_search= GridSearchCV(LogisticRegression(solver='liblinear', multi_class='auto'),param_dist,cv=5)\n",
    "lr_search.fit(x_res,y_res)\n",
    "\n",
    "lr_best = lr_search.best_estimator_ #best classifier found with GridSearchCV\n",
    "   \n",
    "lr_preds = lr_best.predict(x_test)\n",
    "train_preds = lr_best.predict(x_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' The Testing F1 score for Functionality class using LR is', 0.6438383838383839)\n",
      "(' The Traing F1 score for Functionality class using LR is', 0.6537525271279448)\n"
     ]
    }
   ],
   "source": [
    "#calculating microaveraged F1 scores for train and test\n",
    "f1_LR_train = metrics.f1_score(y_res,train_preds,average = 'micro')\n",
    "f1_LR_test = metrics.f1_score(y_test,lr_preds,average = 'micro')\n",
    "\n",
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "#getting the indices for the 5-fold cross validation of the test set (25% of original data)\n",
    "kf = KFold(n_splits=5)\n",
    "k_indices = []\n",
    "for _, test_index in kf.split(x_test):\n",
    "    k_indices.append(test_index)\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = lr_best.predict(x_res)\n",
    "    test_preds = lr_best.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "    #print(i)\n",
    "\n",
    "print(\" The Testing F1 score for Functionality class using LR is\",np.nanmean(f1_test))\n",
    "print(\" The Traing F1 score for Functionality class using LR is\",np.nanmean(f1_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] n_estimators=100, max_depth=30 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=30, score=0.74601210121, total=  11.5s\n",
      "[CV] n_estimators=100, max_depth=30 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=30, score=0.826182618262, total=  11.4s\n",
      "[CV] n_estimators=100, max_depth=30 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   25.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, max_depth=30, score=0.827453407606, total=  11.3s\n",
      "[CV] n_estimators=100, max_depth=30 ..................................\n",
      "[CV]  n_estimators=100, max_depth=30, score=0.836531187676, total=  11.0s\n",
      "[CV] n_estimators=100, max_depth=30 ..................................\n",
      "[CV]  n_estimators=100, max_depth=30, score=0.81562478509, total=  10.9s\n",
      "[CV] n_estimators=70, max_depth=30 ...................................\n",
      "[CV]  n_estimators=70, max_depth=30, score=0.746080858086, total=   8.2s\n",
      "[CV] n_estimators=70, max_depth=30 ...................................\n",
      "[CV]  n_estimators=70, max_depth=30, score=0.82446369637, total=   8.2s\n",
      "[CV] n_estimators=70, max_depth=30 ...................................\n",
      "[CV]  n_estimators=70, max_depth=30, score=0.826353070628, total=   8.1s\n",
      "[CV] n_estimators=70, max_depth=30 ...................................\n",
      "[CV]  n_estimators=70, max_depth=30, score=0.837631524654, total=   8.0s\n",
      "[CV] n_estimators=70, max_depth=30 ...................................\n",
      "[CV]  n_estimators=70, max_depth=30, score=0.813561653256, total=   7.6s\n",
      "[CV] n_estimators=50, max_depth=30 ...................................\n",
      "[CV]  n_estimators=50, max_depth=30, score=0.742436743674, total=   5.9s\n",
      "[CV] n_estimators=50, max_depth=30 ...................................\n",
      "[CV]  n_estimators=50, max_depth=30, score=0.825357535754, total=   5.7s\n",
      "[CV] n_estimators=50, max_depth=30 ...................................\n",
      "[CV]  n_estimators=50, max_depth=30, score=0.824496251977, total=   5.7s\n",
      "[CV] n_estimators=50, max_depth=30 ...................................\n",
      "[CV]  n_estimators=50, max_depth=30, score=0.834468055842, total=   5.5s\n",
      "[CV] n_estimators=50, max_depth=30 ...................................\n",
      "[CV]  n_estimators=50, max_depth=30, score=0.81197991885, total=   5.4s\n",
      "[CV] n_estimators=100, max_depth=25 ..................................\n",
      "[CV]  n_estimators=100, max_depth=25, score=0.74346809681, total=  11.5s\n",
      "[CV] n_estimators=100, max_depth=25 ..................................\n",
      "[CV]  n_estimators=100, max_depth=25, score=0.825220022002, total=  11.3s\n",
      "[CV] n_estimators=100, max_depth=25 ..................................\n",
      "[CV]  n_estimators=100, max_depth=25, score=0.822983288632, total=  11.3s\n",
      "[CV] n_estimators=100, max_depth=25 ..................................\n",
      "[CV]  n_estimators=100, max_depth=25, score=0.836256103432, total=  11.0s\n",
      "[CV] n_estimators=100, max_depth=25 ..................................\n",
      "[CV]  n_estimators=100, max_depth=25, score=0.816587579946, total=  11.0s\n",
      "[CV] n_estimators=70, max_depth=25 ...................................\n",
      "[CV]  n_estimators=70, max_depth=25, score=0.745393289329, total=   8.0s\n",
      "[CV] n_estimators=70, max_depth=25 ...................................\n",
      "[CV]  n_estimators=70, max_depth=25, score=0.822882288229, total=   8.1s\n",
      "[CV] n_estimators=70, max_depth=25 ...................................\n",
      "[CV]  n_estimators=70, max_depth=25, score=0.825940444261, total=   7.8s\n",
      "[CV] n_estimators=70, max_depth=25 ...................................\n",
      "[CV]  n_estimators=70, max_depth=25, score=0.83433051372, total=   7.8s\n",
      "[CV] n_estimators=70, max_depth=25 ...................................\n",
      "[CV]  n_estimators=70, max_depth=25, score=0.807097173509, total=   8.2s\n",
      "[CV] n_estimators=50, max_depth=25 ...................................\n",
      "[CV]  n_estimators=50, max_depth=25, score=0.743674367437, total=   6.2s\n",
      "[CV] n_estimators=50, max_depth=25 ...................................\n",
      "[CV]  n_estimators=50, max_depth=25, score=0.821782178218, total=   6.0s\n",
      "[CV] n_estimators=50, max_depth=25 ...................................\n",
      "[CV]  n_estimators=50, max_depth=25, score=0.824152396671, total=   5.7s\n",
      "[CV] n_estimators=50, max_depth=25 ...................................\n",
      "[CV]  n_estimators=50, max_depth=25, score=0.834192971598, total=   5.5s\n",
      "[CV] n_estimators=50, max_depth=25 ...................................\n",
      "[CV]  n_estimators=50, max_depth=25, score=0.811498521422, total=   5.5s\n",
      "[CV] n_estimators=100, max_depth=20 ..................................\n",
      "[CV]  n_estimators=100, max_depth=20, score=0.739136413641, total=  11.4s\n",
      "[CV] n_estimators=100, max_depth=20 ..................................\n",
      "[CV]  n_estimators=100, max_depth=20, score=0.815319031903, total=  10.9s\n",
      "[CV] n_estimators=100, max_depth=20 ..................................\n",
      "[CV]  n_estimators=100, max_depth=20, score=0.818513169658, total=  11.0s\n",
      "[CV] n_estimators=100, max_depth=20 ..................................\n",
      "[CV]  n_estimators=100, max_depth=20, score=0.82889759989, total=  10.6s\n",
      "[CV] n_estimators=100, max_depth=20 ..................................\n",
      "[CV]  n_estimators=100, max_depth=20, score=0.808059968365, total=  10.7s\n",
      "[CV] n_estimators=70, max_depth=20 ...................................\n",
      "[CV]  n_estimators=70, max_depth=20, score=0.738311331133, total=   8.0s\n",
      "[CV] n_estimators=70, max_depth=20 ...................................\n",
      "[CV]  n_estimators=70, max_depth=20, score=0.814975247525, total=   7.7s\n",
      "[CV] n_estimators=70, max_depth=20 ...................................\n",
      "[CV]  n_estimators=70, max_depth=20, score=0.820369988309, total=   7.8s\n",
      "[CV] n_estimators=70, max_depth=20 ...................................\n",
      "[CV]  n_estimators=70, max_depth=20, score=0.828966370951, total=   7.7s\n",
      "[CV] n_estimators=70, max_depth=20 ...................................\n",
      "[CV]  n_estimators=70, max_depth=20, score=0.809091534282, total=   7.4s\n",
      "[CV] n_estimators=50, max_depth=20 ...................................\n",
      "[CV]  n_estimators=50, max_depth=20, score=0.73803630363, total=   5.9s\n",
      "[CV] n_estimators=50, max_depth=20 ...................................\n",
      "[CV]  n_estimators=50, max_depth=20, score=0.816762926293, total=   5.5s\n",
      "[CV] n_estimators=50, max_depth=20 ...................................\n",
      "[CV]  n_estimators=50, max_depth=20, score=0.817068977374, total=   5.5s\n",
      "[CV] n_estimators=50, max_depth=20 ...................................\n",
      "[CV]  n_estimators=50, max_depth=20, score=0.824977649405, total=   5.4s\n",
      "[CV] n_estimators=50, max_depth=20 ...................................\n",
      "[CV]  n_estimators=50, max_depth=20, score=0.805171583798, total=   5.4s\n",
      "[CV] n_estimators=100, max_depth=5 ...................................\n",
      "[CV]  n_estimators=100, max_depth=5, score=0.609117161716, total=   5.6s\n",
      "[CV] n_estimators=100, max_depth=5 ...................................\n",
      "[CV]  n_estimators=100, max_depth=5, score=0.660478547855, total=   5.4s\n",
      "[CV] n_estimators=100, max_depth=5 ...................................\n",
      "[CV]  n_estimators=100, max_depth=5, score=0.665222474383, total=   5.3s\n",
      "[CV] n_estimators=100, max_depth=5 ...................................\n",
      "[CV]  n_estimators=100, max_depth=5, score=0.676844783715, total=   5.4s\n",
      "[CV] n_estimators=100, max_depth=5 ...................................\n",
      "[CV]  n_estimators=100, max_depth=5, score=0.661783921326, total=   5.3s\n",
      "[CV] n_estimators=70, max_depth=5 ....................................\n",
      "[CV]  n_estimators=70, max_depth=5, score=0.61303630363, total=   4.0s\n",
      "[CV] n_estimators=70, max_depth=5 ....................................\n",
      "[CV]  n_estimators=70, max_depth=5, score=0.663022552255, total=   3.7s\n",
      "[CV] n_estimators=70, max_depth=5 ....................................\n",
      "[CV]  n_estimators=70, max_depth=5, score=0.652018430644, total=   3.8s\n",
      "[CV] n_estimators=70, max_depth=5 ....................................\n",
      "[CV]  n_estimators=70, max_depth=5, score=0.681314902689, total=   4.1s\n",
      "[CV] n_estimators=70, max_depth=5 ....................................\n",
      "[CV]  n_estimators=70, max_depth=5, score=0.674506567636, total=   3.7s\n",
      "[CV] n_estimators=50, max_depth=5 ....................................\n",
      "[CV]  n_estimators=50, max_depth=5, score=0.608292079208, total=   3.5s\n",
      "[CV] n_estimators=50, max_depth=5 ....................................\n",
      "[CV]  n_estimators=50, max_depth=5, score=0.653809130913, total=   3.3s\n",
      "[CV] n_estimators=50, max_depth=5 ....................................\n",
      "[CV]  n_estimators=50, max_depth=5, score=0.663709511038, total=   3.2s\n",
      "[CV] n_estimators=50, max_depth=5 ....................................\n",
      "[CV]  n_estimators=50, max_depth=5, score=0.681108589506, total=   3.3s\n",
      "[CV] n_estimators=50, max_depth=5 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=50, max_depth=5, score=0.665084932261, total=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  8.0min finished\n"
     ]
    }
   ],
   "source": [
    "### RF optimizing hyperparameters\n",
    "parameters = {'n_estimators':(100,70,50),'max_depth':(30,25,20,5)}\n",
    "rf = RandomForestClassifier(criterion = 'entropy',min_samples_leaf = 5, min_samples_split = 10)\n",
    "rf_cv = GridSearchCV(rf,parameters,cv=5,verbose=3)\n",
    "rf_cv.fit(x_res,y_res)\n",
    "\n",
    "rf_best = rf_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test predictions\n",
    "train_rf_pred = rf_best.predict(x_res)\n",
    "rf_pred = rf_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating microaveraged F1 scores for train and test\n",
    "f1_rf_train = metrics.f1_score(y_res,train_rf_pred,average = 'micro')\n",
    "f1_rf_test = metrics.f1_score(y_test,rf_pred,average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Testing F1 score for FUNCTIONALITY class using RF is ', 0.7688888888888888)\n",
      "('The Traing F1 score for FUNCTIONALITY class using Rf is ', 0.8625104867214042)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = rf_best.predict(x_res)\n",
    "    test_preds = rf_best.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "    #print(i)\n",
    "\n",
    "print(\"The Testing F1 score for FUNCTIONALITY class using RF is \",np.nanmean(f1_test))\n",
    "print(\"The Traing F1 score for FUNCTIONALITY class using Rf is \",np.nanmean(f1_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.679249174917, total=  31.4s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   31.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.695200770077, total=  35.1s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.673612543842, total=  20.3s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.710198748367, total=  28.0s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.709098411388, total=  34.2s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.684818481848, total=  26.2s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.696782178218, total=  26.6s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.683240492401, total=  27.7s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.69953923389, total=  30.2s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.713843614607, total=  37.8s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.683787128713, total=  35.8s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.694100660066, total=  32.7s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.684547142562, total=  26.9s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.692799669899, total=  29.3s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.68922357472, total=  27.1s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.685093509351, total=  33.1s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.681449394939, total=  30.3s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.698163812668, total=  33.1s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.683034179217, total=  36.8s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.686128876969, total=  12.3s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.684199669967, total=  33.1s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.690594059406, total=  45.4s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.692662127777, total=  38.2s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.675538133553, total=  20.8s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.69348738051, total=  27.7s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.677805280528, total=  31.8s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.685368536854, total=  37.0s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.685785021663, total=  34.9s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.699264149646, total=  34.6s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.704215666048, total=  32.4s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.590209020902, total=  34.4s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.609598459846, total=  35.1s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.582559658896, total=  35.0s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.652706141256, total=  28.4s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.609311601678, total=  27.4s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.614548954895, total=  30.0s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.612417491749, total=  39.7s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.642871879513, total=  36.5s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.63303761777, total=  42.1s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.649542672443, total=  32.0s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.621562156216, total=  35.0s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.612142464246, total=  35.1s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.593563028678, total=  20.4s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.644384842858, total=  33.3s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.609792999106, total=  25.5s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.62596259626, total=  35.1s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.632563256326, total=  26.4s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.620521284643, total=  35.9s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.638814386906, total=  31.8s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.629942920019, total=  27.9s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.598666116612, total=  35.1s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.622868536854, total=  25.0s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.65600715219, total=  28.5s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.612956467918, total=  18.2s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.615776081425, total=  23.6s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.613930143014, total=  27.4s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.628231573157, total=  35.2s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.625954198473, total=  35.0s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.551543910323, total=  18.0s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.665084932261, total=  35.2s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=12, score=0.679867986799, total=  25.4s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=12, score=0.687775027503, total=  23.4s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=12, score=0.677463723265, total=  22.8s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=12, score=0.697201017812, total=  27.9s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=12, score=0.706003713637, total=  19.5s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12, score=0.686812431243, total=  31.1s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12, score=0.689631463146, total=  28.5s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12, score=0.691905646104, total=  24.5s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12, score=0.694381404305, total=  29.8s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=12, score=0.688192008803, total=  14.7s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12, score=0.68447469747, total=  21.0s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12, score=0.6849559956, total=  11.5s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12, score=0.680008252527, total=  21.4s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12, score=0.701189739358, total=  29.3s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12 \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=12, score=0.704628292415, total=  36.1s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.65848459846, total=  31.3s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.609804730473, total=  14.8s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.667216835156, total=  15.1s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.675813217798, total=  21.9s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.643559590124, total=  28.6s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.644183168317, total=  25.6s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.675742574257, total=  32.5s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.658895536758, total=  17.2s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.68502853999, total=  24.7s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.702152534214, total=  32.7s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.669348184818, total=  24.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.673129812981, total=  35.1s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.679389312977, total=  29.2s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.673475001719, total=  34.4s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.691561790798, total=  21.7s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.66247249725, total=  15.2s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.650371287129, total=  12.8s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.639364555395, total=  19.9s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.679251770855, total=  22.9s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.691699332921, total=  17.5s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.60554180418, total=  17.7s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.601278877888, total=  20.9s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.68379066089, total=  27.2s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.669555051234, total=  19.5s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.674644109759, total=  11.0s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.637995049505, total=  12.9s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.67904290429, total=  22.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.685853792724, total=  20.9s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.675400591431, total=  20.0s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.696994704628, total=  32.1s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.55596809681, total=  18.0s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.562431243124, total=  16.1s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.591362354721, total=  29.5s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.596795268551, total=  28.7s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(6, 4, 1), score=0.572450312908, total=  16.6s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.567244224422, total=  36.0s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.566144114411, total=  16.0s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.587786259542, total=  17.4s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.573481878825, total=  14.0s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(6, 4, 1), score=0.592669004883, total=  14.6s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.547648514851, total=  15.9s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.583608360836, total=  26.5s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.571556289114, total=  15.2s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.588130114848, total=  21.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(6, 4, 1), score=0.554501065951, total=  24.9s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.544279427943, total=  15.7s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.608429592959, total=  26.3s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.624785090434, total=  34.8s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.570387181074, total=  16.7s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=(8, 2, 1), score=0.595763702634, total=  21.0s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.58353960396, total=  14.8s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.564287678768, total=  34.5s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.568186507118, total=  22.0s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.620177429338, total=  14.9s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=(8, 2, 1), score=0.584691561791, total=  19.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.583470847085, total=  19.1s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.606435643564, total=  15.7s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.637645278867, total=  23.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.644797469225, total=  28.8s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1) \n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=(8, 2, 1), score=0.618939550237, total=  32.3s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=12, score=0.665841584158, total=  19.3s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=12, score=0.685849834983, total=  16.9s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=12, score=0.687022900763, total=  15.6s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=12, score=0.690255140637, total=  17.8s\n",
      "[CV] activation=tanh, learning_rate=constant, hidden_layer_sizes=12 ..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, learning_rate=constant, hidden_layer_sizes=12, score=0.694243862183, total=  10.2s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12, score=0.674092409241, total=  25.1s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12, score=0.692106710671, total=  27.5s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12, score=0.67656969947, total=  21.5s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12, score=0.684684684685, total=  11.7s\n",
      "[CV] activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12 \n",
      "[CV]  activation=tanh, learning_rate=invscaling, hidden_layer_sizes=12, score=0.696100680834, total=  14.0s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12, score=0.675673817382, total=  16.7s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12, score=0.663572607261, total=  10.4s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12, score=0.681865071178, total=  12.2s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12, score=0.679801939344, total=  12.3s\n",
      "[CV] activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12 ..\n",
      "[CV]  activation=tanh, learning_rate=adaptive, hidden_layer_sizes=12, score=0.675744446737, total=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 63.9min finished\n"
     ]
    }
   ],
   "source": [
    "## Neural net optimizing hyperparameters\n",
    "\n",
    "nnet = MLPClassifier(alpha=1e-5)\n",
    "\n",
    "parameters ={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(9,5,2), (10,2), (6,4,1), (8,2,1), (12)],\n",
    "'activation': [\"logistic\", \"tanh\"]\n",
    "}\n",
    "\n",
    "nn_cv = GridSearchCV(nnet,parameters,cv=5,verbose=3)\n",
    "nn_cv.fit(x_res,y_res)\n",
    "\n",
    "nn_best = nn_cv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test predictions\n",
    "train_nn_pred = nn_best.predict(x_res)\n",
    "nn_pred = nn_best.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Testing F1 score for FUNCTIONALITY class using NN is ', 0.6732659932659932)\n",
      "('The Traing F1 score for FUNCTIONALITY class using NN is ', 0.7057529122141079)\n"
     ]
    }
   ],
   "source": [
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = nn_best.predict(x_res)\n",
    "    test_preds = nn_best.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "    \n",
    "\n",
    "print(\"The Testing F1 score for FUNCTIONALITY class using NN is \",np.nanmean(f1_test))\n",
    "print(\"The Traing F1 score for FUNCTIONALITY class using NN is \",np.nanmean(f1_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ***2)Predicting the Water Quantity***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant = df.copy()\n",
    "\n",
    "#OHE process for water quality and functionality - used as predictors for water\n",
    "# quantity\n",
    "new_qual = np.asarray(df_quant['quality_group']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_qual)\n",
    "for num,i in enumerate(np.unique(df_quant['quality_group'])):\n",
    "    df_quant['quality_'+str(i)] = a[:,num]\n",
    "df_quant = df_quant.drop(columns = 'quality_group')\n",
    "\n",
    "\n",
    "new_func = np.asarray(df_quant['labels']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False,categories='auto')\n",
    "a = enc.fit_transform(new_func)\n",
    "for num,i in enumerate(np.unique(df_quant['labels'])):\n",
    "    df_quant[str(i)] = a[:,num]\n",
    "df_quant = df_quant.drop(columns = 'labels')\n",
    "\n",
    "#filling NANs with mean of variable\n",
    "df_quant = df_quant.fillna(df_quant.mean())\n",
    "\n",
    "#separating into test (25%) and train (75%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_quant.drop(columns='quantity_group'), df_quant['quantity_group'], test_size=0.25)\n",
    "\n",
    "#five classes of our output variable\n",
    "classes_quant = ['Dry', 'Enough', 'Insufficient', 'Seasonal','Unknown']\n",
    "\n",
    "#Encoding the five output classes into integers\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(y_train)\n",
    "train_labels = enc.transform(y_train)\n",
    "\n",
    "# SMOTE resampling to deal with class imbalance\n",
    "sm = SMOTE()\n",
    "x_res,y_res = sm.fit_resample(x_train,y_train)\n",
    "\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(y_res)\n",
    "train_labels = enc.transform(y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_res,train_labels)\n",
    "y_pred=logreg.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#optimizing hyperparameters\n",
    "\"\"\"\n",
    "We used GridSearchCV which performs k-fold cross validation (k=5 for us) and searches\n",
    "a grid of specified parameters to find the best parameters.\n",
    "\"\"\"\n",
    "param_dist = {\n",
    "'penalty': ['l1','l2'],\n",
    "'C': [0.001,0.01,0.5,1]\n",
    "}\n",
    "\n",
    "lr_search= GridSearchCV(LogisticRegression(solver='liblinear', multi_class='auto'),param_dist,cv=5)\n",
    "lr_search.fit(x_res,y_res)\n",
    "\n",
    "lr_best_qt = lr_search.best_estimator_ #best classifier found with GridSearchCV\n",
    "\n",
    "lr_preds = lr_best_qt.predict(x_test)\n",
    "train_preds = lr_best_qt.predict(x_res)\n",
    "\n",
    "\n",
    "#calculating microaveraged F1 scores for train and test\n",
    "f1_LR_train = metrics.f1_score(y_res,train_preds,average = 'micro')\n",
    "f1_LR_test = metrics.f1_score(y_test,lr_preds,average = 'micro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' The Testing F1 score for Water Quantity class using LR is', 0.5756902356902357)\n",
      "(' The Traing F1 score for water Quantity class using LR is', 0.6860356213728237)\n"
     ]
    }
   ],
   "source": [
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "#getting the indices for the 5-fold cross validation of the test set (25% of original data)\n",
    "kf = KFold(n_splits=5)\n",
    "k_indices = []\n",
    "for _, test_index in kf.split(x_test):\n",
    "    k_indices.append(test_index)\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = lr_best_qt.predict(x_res) \n",
    "    test_preds = lr_best_qt.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "print(\" The Testing F1 score for Water Quantity class using LR is\",np.nanmean(f1_test))\n",
    "print(\" The Traing F1 score for water Quantity class using LR is\",np.nanmean(f1_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, max_depth=6, score=0.642025215129, total=   1.7s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, max_depth=6, score=0.610206123674, total=   1.8s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, max_depth=6, score=0.661717030218, total=   1.6s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n",
      "[CV]  n_estimators=10, max_depth=6, score=0.657354412648, total=   1.7s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n",
      "[CV]  n_estimators=10, max_depth=6, score=0.657154292576, total=   1.5s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.595317190314, total=   1.1s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.616289773864, total=   1.1s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.646507904743, total=   1.2s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.655033019812, total=   1.2s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.660436261757, total=   1.3s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.581588953372, total=   0.8s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.584470682409, total=   0.7s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.634740844507, total=   0.7s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.616770062037, total=   0.7s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.623013808285, total=   0.8s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.572143285972, total=   0.4s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.540884530718, total=   0.4s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.552531518911, total=   0.5s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.572703622173, total=   0.4s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.580348208925, total=   0.4s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.558935361217, total=   1.4s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.576545927557, total=   1.2s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.599799879928, total=   1.3s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.564298579147, total=   1.3s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.586351811087, total=   1.2s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.534200520312, total=   0.9s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.562377426456, total=   1.0s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.586231739043, total=   0.9s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.603482089254, total=   0.9s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.581909145487, total=   0.8s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV] . n_estimators=4, max_depth=4, score=0.54852911747, total=   0.5s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.575545327196, total=   0.5s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.589633780268, total=   0.5s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.545287172303, total=   0.6s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.579147488493, total=   0.5s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV] . n_estimators=2, max_depth=4, score=0.40572343406, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.528357014209, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.500220132079, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.476525915549, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.431458875325, total=   0.3s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.52619571743, total=   0.9s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.534200520312, total=   0.9s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.55769461677, total=   1.0s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.557734640784, total=   1.0s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.568341004603, total=   1.0s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.564258555133, total=   0.7s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.515429257555, total=   0.7s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.589433660196, total=   0.7s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.548809285571, total=   0.7s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.562977786672, total=   0.7s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV] . n_estimators=4, max_depth=3, score=0.55161096658, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.541845107064, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.525515309186, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.538363017811, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV] . n_estimators=4, max_depth=3, score=0.49641785071, total=   0.5s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.448469081449, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.447948769262, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.509185511307, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.498298979388, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.496177706624, total=   0.3s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, max_depth=2, score=0.549289573744, total=   0.7s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV]  n_estimators=10, max_depth=2, score=0.540484290574, total=   0.9s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV]  n_estimators=10, max_depth=2, score=0.551771062638, total=   0.7s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV]  n_estimators=10, max_depth=2, score=0.517390434261, total=   0.7s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV]  n_estimators=10, max_depth=2, score=0.549729837903, total=   0.7s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.493856313788, total=   0.5s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.510186111667, total=   0.5s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.575985591355, total=   0.5s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.509025415249, total=   0.5s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.521112667601, total=   0.6s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.423253952371, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.426295777466, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.427296377827, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.413007804683, total=   0.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.463317990794, total=   0.3s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.533880328197, total=   0.2s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.371302781669, total=   0.2s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.484890934561, total=   0.2s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.416810086052, total=   0.2s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.336321793076, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "### RF optimizing hyperparameters\n",
    "parameters = {'n_estimators':(10,7,4,2),'max_depth':(6,4,3,2)}\n",
    "rf = RandomForestClassifier(criterion = 'entropy',min_samples_leaf = 5, min_samples_split = 10)\n",
    "rf_cv = GridSearchCV(rf,parameters,cv=5,verbose=3)\n",
    "rf_cv.fit(x_res,y_res)\n",
    "\n",
    "rf_best_qt = rf_cv.best_estimator_\n",
    "\n",
    "#train and test predictions\n",
    "train_rf_pred = rf_best_qt.predict(x_res)\n",
    "rf_pred = rf_best_qt.predict(x_test)\n",
    "\n",
    "#calculating microaveraged F1 scores for train and test\n",
    "f1_rf_train = metrics.f1_score(y_res,train_rf_pred,average = 'micro')\n",
    "f1_rf_test = metrics.f1_score(y_test,rf_pred,average = 'micro')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Testing F1 score for Water Quantity class using RF is 78.9544578962145867\n",
      "The Traing F1 score for Water Quantity class using Rf is 91.97852462153654852 \n"
     ]
    }
   ],
   "source": [
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = rf_best_qt.predict(x_res)\n",
    "    test_preds = rf_best_qt.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "    \n",
    "\n",
    "\n",
    "print(\"The Testing F1 score for Water Quantity class using RF is \",np.nanmean(f1_test))\n",
    "print(\"The Traing F1 score for Water Quantity class using Rf is \",np.nanmean(f1_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.619051430859, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.648429057434, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.676285771463, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.641184710826, total=  47.9s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(9, 5, 2), score=0.65819491695, total= 1.0min\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.650590354213, total= 1.2min\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.656914148489, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.668160896538, total=  52.6s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.66836101661, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(9, 5, 2), score=0.655273163898, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.654552731639, total=  43.7s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.655753452071, total=  47.4s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.66191715029, total=  49.6s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.669481689013, total=  56.6s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(9, 5, 2), score=0.662957774665, total= 1.2min\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.642825695417, total=  41.3s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.659995997599, total=  51.8s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.660756453872, total=  35.1s\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.6605563338, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=constant, hidden_layer_sizes=(10, 2), score=0.648789273564, total=  30.9s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.650310186112, total= 1.0min\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.654752851711, total=  33.2s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.668961376826, total=  37.4s\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.66291775065, total= 1.1min\n",
      "[CV] activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=invscaling, hidden_layer_sizes=(10, 2), score=0.655553331999, total=  57.2s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.651430858515, total= 1.0min\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.682729637783, total= 1.0min\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.655713428057, total=  40.1s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n",
      "[CV]  activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2), score=0.670562337402, total=  55.2s\n",
      "[CV] activation=logistic, learning_rate=adaptive, hidden_layer_sizes=(10, 2) \n"
     ]
    }
   ],
   "source": [
    "## Neural net optimizing hyperparameters\n",
    "\n",
    "nnet = MLPClassifier(alpha=1e-5)\n",
    "\n",
    "parameters ={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(9,5,2), (10,2), (6,4,1), (8,2,1), (12)],\n",
    "'activation': [\"logistic\", \"tanh\"]\n",
    "}\n",
    "\n",
    "nn_cv = GridSearchCV(nnet,parameters,cv=5,verbose=3)\n",
    "nn_cv.fit(x_res,y_res)\n",
    "\n",
    "nn_best_qt = nn_cv.best_estimator_\n",
    "\n",
    "#train and test predictions\n",
    "train_nn_pred = nn_best_qt.predict(x_res)\n",
    "nn_pred = nn_best_qt.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Testing F1 score for Water Quantity class using NN is 66.4254635784215632\n",
      "The Traing F1 score for Water Quantity class using NN is 79.648534535421562\n"
     ]
    }
   ],
   "source": [
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = nn_best_qt.predict(x_res)\n",
    "    test_preds = nn_best_qt.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "    \n",
    "print(\"The Testing F1 score for Water Quantity class using NN is \",np.nanmean(f1_test))\n",
    "print(\"The Traing F1 score for Water Quantity class using NN is \",np.nanmean(f1_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ***3)Predicting the water quality***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual=df.copy()\n",
    "#OHE process for quantity and functionality - used as predictors for water quality\n",
    "new_quant = np.asarray(df_qual['quantity_group']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False)\n",
    "a = enc.fit_transform(new_quant)\n",
    "for num,i in enumerate(np.unique(df_qual['quantity_group'])):\n",
    "    df_qual['quantity_'+str(i)] = a[:,num]\n",
    "df_qual = df_qual.drop(columns = 'quantity_group')\n",
    "\n",
    "\n",
    "new_func = np.asarray(df_qual['labels']).reshape(-1,1)\n",
    "enc = preprocessing.OneHotEncoder(sparse= False)\n",
    "a = enc.fit_transform(new_func)\n",
    "for num,i in enumerate(np.unique(df_qual['labels'])):\n",
    "    df_qual[str(i)] = a[:,num]\n",
    "df_qual = df_qual.drop(columns = 'labels')\n",
    "\n",
    "#filling NANs with mean of variable\n",
    "df_qual = df_qual.fillna(df_qual.mean())\n",
    "\n",
    "#separating into test (25%) and train (75%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_qual.drop(columns='quality_group'), df_qual['quality_group'], test_size=0.25)\n",
    "\n",
    "#six classes of our output variable\n",
    "classes_qual = ['Colored', 'Fluoride', 'Good', 'Milky','Salty', 'Unknown']\n",
    "\n",
    "#Encoding the output classes into integers\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(y_train)\n",
    "train_labels = enc.transform(y_train)\n",
    "\n",
    "# SMOTE resampling to deal with class imbalance\n",
    "sm = SMOTE()\n",
    "x_res,y_res = sm.fit_resample(x_train,y_train)\n",
    "\n",
    "enc = preprocessing.LabelEncoder()\n",
    "enc.fit(y_res)\n",
    "train_labels = enc.transform(y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\DELL\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## LR\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_res,train_labels)\n",
    "y_pred=logreg.predict(x_test)\n",
    "\n",
    "\n",
    "#optimizing hyperparameters\n",
    "\"\"\"\n",
    "We used GridSearchCV which performs k-fold cross validation (k=5 for us) and searches\n",
    "a grid of specified parameters to find the best parameters.\n",
    "\"\"\"\n",
    "param_dist = {\n",
    "'penalty': ['l1','l2'],\n",
    "'C': [0.001,0.01,0.5,1]\n",
    "}\n",
    "\n",
    "lr_search= GridSearchCV(LogisticRegression(solver='liblinear', multi_class='auto'),param_dist,cv=5)\n",
    "lr_search.fit(x_res,y_res)\n",
    "\n",
    "lr_best_ql = lr_search.best_estimator_ #best classifier found with GridSearchCV\n",
    "\n",
    "lr_preds = lr_best_ql.predict(x_test)\n",
    "train_preds = lr_best_ql.predict(x_res)\n",
    "\n",
    "\n",
    "#calculating microaveraged F1 scores for train and test\n",
    "f1_LR_train = metrics.f1_score(y_res,train_preds,average = 'micro')\n",
    "f1_LR_test = metrics.f1_score(y_test,lr_preds,average = 'micro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Testing F1 score for Water Quality class using LR is 59.84562145793524586\n",
      " The Traing F1 score for water Quality class using LR is 77.05896321452545248\n"
     ]
    }
   ],
   "source": [
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "#getting the indices for the 5-fold cross validation of the test set (25% of original data)\n",
    "kf = KFold(n_splits=5)\n",
    "k_indices = []\n",
    "for _, test_index in kf.split(x_test):\n",
    "    k_indices.append(test_index)\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = lr_best_ql.predict(x_res)\n",
    "    test_preds = lr_best_ql.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "    \n",
    "print(\" The Testing F1 score for Water Quality class using LR is\",np.nanmean(f1_test))\n",
    "print(\" The Traing F1 score for water Quality class using LR is\",np.nanmean(f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=10, max_depth=6 ....................................\n",
      "[CV]  n_estimators=10, max_depth=6, score=0.748784973072, total=   6.5s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, max_depth=6, score=0.732694075923, total=   6.1s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, max_depth=6, score=0.745107053724, total=   6.5s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n",
      "[CV]  n_estimators=10, max_depth=6, score=0.725521107024, total=   6.5s\n",
      "[CV] n_estimators=10, max_depth=6 ....................................\n",
      "[CV]  n_estimators=10, max_depth=6, score=0.731213872832, total=   6.2s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.721704102631, total=   4.9s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.733854371908, total=   4.9s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.709115985814, total=   4.6s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.735330180417, total=   4.5s\n",
      "[CV] n_estimators=7, max_depth=6 .....................................\n",
      "[CV]  n_estimators=7, max_depth=6, score=0.723791382028, total=   4.6s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.696900039406, total=   2.7s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.716931564429, total=   3.0s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.691383160384, total=   3.3s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.698787002978, total=   3.0s\n",
      "[CV] n_estimators=4, max_depth=6 .....................................\n",
      "[CV]  n_estimators=4, max_depth=6, score=0.689131196357, total=   2.9s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.631332370069, total=   1.7s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.669884846097, total=   1.8s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.611322737423, total=   1.7s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.644333508495, total=   1.7s\n",
      "[CV] n_estimators=2, max_depth=6 .....................................\n",
      "[CV]  n_estimators=2, max_depth=6, score=0.645515852163, total=   1.8s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.64538727615, total=   4.2s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.660602478217, total=   4.3s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.647554621481, total=   4.8s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.652303380627, total=   4.6s\n",
      "[CV] n_estimators=10, max_depth=4 ....................................\n",
      "[CV]  n_estimators=10, max_depth=4, score=0.640304781923, total=   4.5s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.639016594422, total=   3.5s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.634703796138, total=   3.8s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.629340163755, total=   3.3s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.657623927133, total=   3.3s\n",
      "[CV] n_estimators=7, max_depth=4 .....................................\n",
      "[CV]  n_estimators=7, max_depth=4, score=0.639034857243, total=   3.5s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.577827400499, total=   2.1s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.612461141031, total=   2.1s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.613730898901, total=   2.2s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.608053074094, total=   2.2s\n",
      "[CV] n_estimators=4, max_depth=4 .....................................\n",
      "[CV]  n_estimators=4, max_depth=4, score=0.608403398143, total=   2.2s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.538990323569, total=   1.4s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.499299443934, total=   1.4s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.518542843382, total=   1.3s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.580793483973, total=   1.4s\n",
      "[CV] n_estimators=2, max_depth=4 .....................................\n",
      "[CV]  n_estimators=2, max_depth=4, score=0.498620599054, total=   1.3s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.623188405797, total=   3.8s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.64127150926, total=   3.8s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.638162791716, total=   3.7s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.621431073743, total=   3.1s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV]  n_estimators=10, max_depth=3, score=0.614139954458, total=   4.2s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.549411095057, total=   2.8s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.544156924559, total=   2.7s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.585511624852, total=   2.5s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.569867752671, total=   2.8s\n",
      "[CV] n_estimators=7, max_depth=3 .....................................\n",
      "[CV]  n_estimators=7, max_depth=3, score=0.565335435278, total=   2.8s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.558321292526, total=   2.0s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.567231489995, total=   1.9s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.553548754324, total=   1.8s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.529668067963, total=   1.7s\n",
      "[CV] n_estimators=4, max_depth=3 .....................................\n",
      "[CV]  n_estimators=4, max_depth=3, score=0.580333683657, total=   1.8s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.501335435002, total=   1.2s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.507968825255, total=   1.2s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.473422654232, total=   1.2s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.516793659135, total=   1.3s\n",
      "[CV] n_estimators=2, max_depth=3 .....................................\n",
      "[CV]  n_estimators=2, max_depth=3, score=0.527741285689, total=   1.2s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=10, max_depth=2, score=0.570121283769, total=   2.7s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV] . n_estimators=10, max_depth=2, score=0.5612110863, total=   2.7s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV]  n_estimators=10, max_depth=2, score=0.532532072332, total=   2.8s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV]  n_estimators=10, max_depth=2, score=0.576348747592, total=   2.8s\n",
      "[CV] n_estimators=10, max_depth=2 ....................................\n",
      "[CV]  n_estimators=10, max_depth=2, score=0.555592047644, total=   2.6s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.553089014405, total=   2.0s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.519900170761, total=   2.0s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.519812601252, total=   2.0s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.543265020144, total=   2.0s\n",
      "[CV] n_estimators=7, max_depth=2 .....................................\n",
      "[CV]  n_estimators=7, max_depth=2, score=0.556752496059, total=   2.2s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.498401856474, total=   1.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.487171067034, total=   1.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.460002627085, total=   1.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.499146085129, total=   1.4s\n",
      "[CV] n_estimators=4, max_depth=2 .....................................\n",
      "[CV]  n_estimators=4, max_depth=2, score=0.439590996672, total=   1.2s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.393208984632, total=   1.0s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.470795568983, total=   0.9s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.398572617015, total=   0.9s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.432518829918, total=   1.1s\n",
      "[CV] n_estimators=2, max_depth=2 .....................................\n",
      "[CV]  n_estimators=2, max_depth=2, score=0.430394990366, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  4.7min finished\n"
     ]
    }
   ],
   "source": [
    "### RF optimizing hyperparameters\n",
    "parameters = {'n_estimators':(10,7,4,2),'max_depth':(6,4,3,2)}\n",
    "rf = RandomForestClassifier(criterion = 'entropy',min_samples_leaf = 5, min_samples_split = 10)\n",
    "rf_cv = GridSearchCV(rf,parameters,cv=5,verbose=3)\n",
    "rf_cv.fit(x_res,y_res)\n",
    "\n",
    "rf_best_ql = rf_cv.best_estimator_\n",
    "\n",
    "#train and test predictions\n",
    "train_rf_pred = rf_best_ql.predict(x_res)\n",
    "rf_pred = rf_best_ql.predict(x_test)\n",
    "\n",
    "#calculating microaveraged F1 scores for train and test\n",
    "f1_rf_train = metrics.f1_score(y_res,train_rf_pred,average = 'micro')\n",
    "f1_rf_test = metrics.f1_score(y_test,rf_pred,average = 'micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Testing F1 score for Water Quality class using RF is  97.4152952175248564\n",
      "The Traing F1 score for Water Quality class using Rf is 97.921547863215462\n"
     ]
    }
   ],
   "source": [
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "k_indices = []\n",
    "for _, test_index in kf.split(x_test):\n",
    "    k_indices.append(test_index)\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = rf_best_ql.predict(x_res)\n",
    "    test_preds = rf_best_ql.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "    \n",
    "\n",
    "print(\"The Testing F1 score for Water Quality class using RF is \",np.nanmean(f1_test))\n",
    "print(\"The Traing F1 score for Water Quality class using Rf is \",np.nanmean(f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = MLPClassifier(alpha=1e-5)\n",
    "\n",
    "parameters ={\n",
    "'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(9,5,2), (10,2), (6,1), (8,2,1), (12)],\n",
    "'activation': [\"logistic\", \"tanh\"]\n",
    "}\n",
    "\n",
    "nn_cv = GridSearchCV(nnet,parameters,cv=5,verbose=3)\n",
    "nn_cv.fit(x_res,y_res)\n",
    "\n",
    "nn_best_ql = nn_cv.best_estimator_\n",
    "\n",
    "#train and test predictions\n",
    "train_nn_pred = nn_best_ql.predict(x_res)\n",
    "nn_pred = nn_best_ql.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Testing F1 score for Water Quality class using NN is 73.3588452556987742\n",
      "The Traing F1 score for Water Quality class using NN is 91.0485524661578962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Performing 5-fold CV on test set:\n",
    "f1_train = []\n",
    "f1_test = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    inds = k_indices[i]\n",
    "    x_t,y_t = np.asarray(x_test)[inds],np.asarray(y_test)[inds]\n",
    "    train_preds = nn_best_ql.predict(x_res)\n",
    "    test_preds = nn_best_ql.predict(x_t)\n",
    "    f1_train.append(metrics.f1_score(y_res,train_preds,average = \"micro\"))\n",
    "    f1_test.append(metrics.f1_score(y_t,test_preds,average = \"micro\"))\n",
    "print(\"The Testing F1 score for Water Quality class using NN is \",np.nanmean(f1_test))\n",
    "print(\"The Traing F1 score for Water Quality class using NN is \",np.nanmean(f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
